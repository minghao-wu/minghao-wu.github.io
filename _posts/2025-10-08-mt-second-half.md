---
title: 'On The Second Half of Machine Translation'
date: 2025-10-08
permalink: /posts/2025-10-08-mt-second-half
tags:
  - cool posts
  - category1
  - category2
mathjax: true
---

Many think that machine translation (MT) is a solved problem, but is it really? While significant progress has been made with models like GPT-4 and other large language models, challenges remain.

After the release of ChatGPT in late 2022, many believed that MT was effectively "solved". In my own analysis of the arXiv submissions, I observed that the last burst of MT papers occurred around mid-2023. Since then, the number of MT-related submissions has decreased significantly, suggesting a decline in research interest.

However, **is MT truly dead?** I would argue that it is not, given what I experienced at ACL2025, Vienna, Austria. I fluently speak and write in both English and Chinese, but struggled with ordering food deliveries via an app in German. **So, what's the second half of machine translation?**

## The First Half

The first half of machine translation primarily focused on improving the translation quality. Early approaches included rule-based systems, which relied on linguistic rules and dictionaries to perform translations. These systems were limited by their inability to handle the complexities and nuances of natural language. Then, statistical machine translation (SMT) emerged, leveraging large parallel corpora to learn translation patterns. SMT significantly improved translation quality but still struggled with fluency and context. Next, neural machine translation (NMT) revolutionized the field by using deep learning techniques to model the entire translation process. NMT systems, particularly those based on the Transformer architecture, achieved state-of-the-art results and became the dominant approach in MT.

More recently, large language models (LLMs) like GPT-4 have demonstrated impressive zero-shot and few-shot translation capabilities. These models can generate high-quality translations without task-specific training, making them versatile and powerful tools for MT. Recent studies even claim that human evaluators often prefer translations generated by LLMs over those produced by human translators.

## The Second Half

Current MT systems can even perform on par or better than human translators in certain scenarios. So, what is the next step? Where should MT research go from here?

I believe that the second half of machine translation should start from the evaluation perspective. Although some researches claim that their approaches outperform humans, are they really better than humans? In my opinion, the answer is no, even though one of my own papers made such a claim. The reason is that current evaluation metrics, such as BLEU, METEOR, and ROUGE, primarily focus on surface-level similarities between the generated translation and reference translations. These metrics often fail to capture deeper aspects of translation quality, such as fluency, adequacy, and cultural nuances.